{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dd1937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e009a83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHARS = list(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\")\n",
    "IDX_TO_CHAR = {idx: char for idx, char in enumerate(CHARS)}\n",
    "SEQ_LENGTH = 6\n",
    "VOCAB_SIZE = len(CHARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a016443a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OCRModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OCRModel, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(256 * 16 * 16, 512)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.heads = nn.ModuleList([nn.Linear(512, VOCAB_SIZE) for _ in range(SEQ_LENGTH)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.cnn(x)\n",
    "        features = self.flatten(features)\n",
    "        features = self.relu(self.fc(features))\n",
    "        outputs = [head(features) for head in self.heads]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba25987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, image_path, device):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        predictions = [torch.argmax(o, dim=1).item() for o in outputs]\n",
    "        predicted_label = ''.join([IDX_TO_CHAR[idx] for idx in predictions])\n",
    "    return predicted_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bddf8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model = OCRModel()\n",
    "    model.load_state_dict(torch.load(\"ocr_model.pth\", map_location=\"cpu\"))\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # ðŸ”¥ Test on one image\n",
    "    test_image_path = \"test_image.jpg\"  # <-- put your test image here\n",
    "    prediction = predict(model, test_image_path, device)\n",
    "    print(f\"Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446deda6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b3ae57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85857a43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
